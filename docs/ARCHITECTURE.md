# ARCHITECTURE.md

本文件描述 Agentic Compression Framework 的系統架構。

```
╔══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                          AGENTIC COMPRESSION FRAMEWORK - 系統架構圖                                    ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════╝

┌─────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                         使用者輸入層                                                   │
│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐          │
│  │   model_name    │    │    dataset      │    │  max_episodes   │    │  budget_hours   │          │
│  │ (gpt2, llama..) │    │ (gsm8k, mmlu..) │    │     (10)        │    │    (4.0)        │          │
│  └────────┬────────┘    └────────┬────────┘    └────────┬────────┘    └────────┬────────┘          │
│           └──────────────────────┴──────────────────────┴──────────────────────┘                    │
└─────────────────────────────────────────────────────────────────────────────────────────────────────┘
                                                  │
                                                  ▼
┌─────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                  規格推論層 (Spec Inference)                                          │
│                                 src/coordinator/spec_inference.py                                    │
│  ┌───────────────────────────────────────────────────────────────────────────────────────────────┐  │
│  │                                    infer_spec()                                                │  │
│  │  ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐        │  │
│  │  │ HuggingFace Hub │──►│ MODEL_SIZE_DB   │──►│  Regex 解析      │──►│  ModelSpec      │        │  │
│  │  │    API 查詢      │   │  (100+ models)  │   │ (7b→14GB)       │   │  輸出           │        │  │
│  │  └─────────────────┘   └─────────────────┘   └─────────────────┘   └────────┬────────┘        │  │
│  └───────────────────────────────────────────────────────────────────────────────┘                │  │
└─────────────────────────────────────────────────────────────────────────────────────────────────────┘
                                                  │
                    ┌─────────────────────────────┴─────────────────────────────┐
                    ▼                                                           ▼
            ┌──────────────────┐                                    ┌──────────────────┐
            │    ModelSpec     │                                    │ Preferred Methods│
            │  model_size_gb   │                                    │  Small: AUTOROUND│
            │  min_vram_gb     │                                    │  Medium: GPTQ/AWQ│
            │  model_family    │                                    │  Large: GPTQ 4bit│
            └────────┬─────────┘                                    └────────┬─────────┘
                     └────────────────────────┬─────────────────────────────┘
                                              ▼
╔══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                    LANGGRAPH 狀態機核心                                                ║
║                              src/coordinator/langgraph_coordinator.py                                 ║
╠══════════════════════════════════════════════════════════════════════════════════════════════════════╣
║                                                                                                       ║
║  ┌─────────────────────────────────────────────────────────────────────────────────────────────────┐ ║
║  │                              CompressionState (src/coordinator/state.py)                         │ ║
║  │  ┌───────────────┐ ┌───────────────┐ ┌───────────────┐ ┌───────────────┐ ┌───────────────┐      │ ║
║  │  │ model_name    │ │ current_      │ │ history[]     │ │ pareto_       │ │ messages[]    │      │ ║
║  │  │ dataset       │ │ episode       │ │ (max 100)     │ │ frontier[]    │ │ (LLM context) │      │ ║
║  │  │ model_spec    │ │ max_episodes  │ │ strategy+     │ │ optimal       │ │ add_messages  │      │ ║
║  │  │ budget_hours  │ │ budget_hours  │ │ result        │ │ solutions     │ │ reducer       │      │ ║
║  │  └───────────────┘ └───────────────┘ └───────────────┘ └───────────────┘ └───────────────┘      │ ║
║  │  ┌───────────────┐ ┌───────────────┐ ┌───────────────┐ ┌───────────────┐ ┌───────────────┐      │ ║
║  │  │ current_      │ │ compressed_   │ │ next_action   │ │ should_       │ │ skill_        │      │ ║
║  │  │ strategy      │ │ model_path    │ │ (決定下一步)   │ │ terminate     │ │ recommendations│     │ ║
║  │  │ current_result│ │ compression_  │ │ action_params │ │ termination_  │ │ pipeline_     │      │ ║
║  │  │               │ │ ratio         │ │               │ │ reason        │ │ step_index    │      │ ║
║  │  └───────────────┘ └───────────────┘ └───────────────┘ └───────────────┘ └───────────────┘      │ ║
║  └─────────────────────────────────────────────────────────────────────────────────────────────────┘ ║
║                                              │                                                        ║
║                                              ▼                                                        ║
║  ┌─────────────────────────────────────────────────────────────────────────────────────────────────┐ ║
║  │                                     [START]                                                      │ ║
║  │                                        │                                                         │ ║
║  │                                        ▼                                                         │ ║
║  │  ╔═══════════════════════════════════════════════════════════════════════════════════════════╗  │ ║
║  │  ║                           COORDINATOR NODE (GPT-4o)                                        ║  │ ║
║  │  ║  ┌─────────────────────────────────────────────────────────────────────────────────────┐  ║  │ ║
║  │  ║  │                              _coordinator_node()                                     │  ║  │ ║
║  │  ║  │                                                                                      │  ║  │ ║
║  │  ║  │  1. 檢查終止條件 ────────────────────────────────────────────────────────► [END]     │  ║  │ ║
║  │  ║  │     • max_episodes reached?                                                          │  ║  │ ║
║  │  ║  │     • time_budget exceeded?                                                          │  ║  │ ║
║  │  ║  │     • convergence? (5 次無改進)                                                       │  ║  │ ║
║  │  ║  │                                                                                      │  ║  │ ║
║  │  ║  │  2. 建構 LLM Context:                                                                │  ║  │ ║
║  │  ║  │     ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │  ║  │ ║
║  │  ║  │     │ Pareto      │  │ 最近 5 次   │  │ Skill       │  │ CO2         │              │  ║  │ ║
║  │  ║  │     │ Frontier    │  │ History     │  │ Memory      │  │ Metrics     │              │  ║  │ ║
║  │  ║  │     │ 摘要        │  │ 回顧        │  │ 推薦        │  │ 分析        │              │  ║  │ ║
║  │  ║  │     └─────────────┘  └─────────────┘  └─────────────┘  └─────────────┘              │  ║  │ ║
║  │  ║  │                                                                                      │  ║  │ ║
║  │  ║  │  3. 呼叫 GPT-4o API (OpenAI)                                                         │  ║  │ ║
║  │  ║  │                                                                                      │  ║  │ ║
║  │  ║  │  4. 解析 JSON 決策:                                                                  │  ║  │ ║
║  │  ║  │     {                                                                                │  ║  │ ║
║  │  ║  │       "action": "quantization|asvd|lora|qlora|pruning|pipeline|search|end",         │  ║  │ ║
║  │  ║  │       "method": "autoround|gptq|int8|awq",                                          │  ║  │ ║
║  │  ║  │       "bits": 4 or 8,                                                               │  ║  │ ║
║  │  ║  │       "rank_ratio": 0.5,                                                            │  ║  │ ║
║  │  ║  │       "reasoning": "..."                                                            │  ║  │ ║
║  │  ║  │     }                                                                                │  ║  │ ║
║  │  ║  └─────────────────────────────────────────────────────────────────────────────────────┘  ║  │ ║
║  │  ╚═══════════════════════════════════════════════════════════════════════════════════════════╝  │ ║
║  │                                              │                                                   │ ║
║  │                    ┌─────────────────────────┼─────────────────────────┐                         │ ║
║  │                    │                         │                         │                         │ ║
║  │         next_action="quantization"  next_action="pruning"    next_action="pipeline"              │ ║
║  │         next_action="asvd|lora|qlora"                       next_action="search"                 │ ║
║  │                    │                         │                         │                         │ ║
║  │                    ▼                         ▼                         ▼                         │ ║
║  │  ┌─────────────────────────┐ ┌─────────────────────────┐ ┌─────────────────────────┐             │ ║
║  │  │   QUANTIZATION NODE     │ │    PRUNING NODE         │ │    PIPELINE NODE        │             │ ║
║  │  │ ─────────────────────── │ │ ─────────────────────── │ │ ─────────────────────── │             │ ║
║  │  │ @tool quantize_model()  │ │ @tool prune_model()     │ │ Pipeline Templates:     │             │ ║
║  │  │ @tool apply_lora()      │ │   • magnitude pruning   │ │ • aggressive_compression│             │ ║
║  │  │ @tool apply_qlora()     │ │   • structured pruning  │ │ • balanced_quality      │             │ ║
║  │  │ @tool apply_asvd()      │ │                         │ │ • quick_eval            │             │ ║
║  │  │                         │ │ sparsity: 0.1-0.9       │ │ • accuracy_focus        │             │ ║
║  │  │ Methods:                │ │ granularity: layer/head │ │                         │             │ ║
║  │  │ • AUTOROUND (4/8bit)    │ │                         │ │ Step1 → Step2 → Step3   │             │ ║
║  │  │ • GPTQ (4/8bit)         │ │                         │ │ (條件式執行)             │             │ ║
║  │  │ • AWQ (4/8bit)          │ └─────────────────────────┘ └─────────────────────────┘             │ ║
║  │  │ • INT8 (8bit)           │               │                         │                           │ ║
║  │  │ • ASVD (rank_ratio)     │               │                         │                           │ ║
║  │  │ • LoRA (rank=16)        │ ┌─────────────────────────┐             │                           │ ║
║  │  │ • QLoRA (rank+4bit)     │ │     SEARCH NODE         │             │                           │ ║
║  │  └─────────────────────────┘ │ ─────────────────────── │             │                           │ ║
║  │              │               │ @tool bayesian_search() │             │                           │ ║
║  │              │               │ @tool evolutionary()    │◄────────────┘                           │ ║
║  │              │               │ @tool bandit_search()   │                                         │ ║
║  │              │               │ @tool pbt_search()      │                                         │ ║
║  │              │               └─────────────────────────┘                                         │ ║
║  │              │                         │                                                         │ ║
║  │              └────────────┬────────────┴────────────────────────────────────┐                    │ ║
║  │                           │                                                  │                    │ ║
║  │                           ▼                                                  │                    │ ║
║  │  ╔═══════════════════════════════════════════════════════════════════════╗  │                    │ ║
║  │  ║                         EVALUATION NODE                                ║  │                    │ ║
║  │  ║  ┌─────────────────────────────────────────────────────────────────┐  ║  │                    │ ║
║  │  ║  │  src/agents/evaluation_agent.py + src/evaluation/               │  ║  │                    │ ║
║  │  ║  │                                                                  │  ║  │                    │ ║
║  │  ║  │  @tool evaluate_model()                                          │  ║  │                    │ ║
║  │  ║  │  @tool measure_inference_latency()                               │  ║  │                    │ ║
║  │  ║  │  @tool measure_memory_usage()                                    │  ║  │                    │ ║
║  │  ║  │  @tool estimate_energy_consumption()                             │  ║  │                    │ ║
║  │  ║  │                                                                  │  ║  │                    │ ║
║  │  ║  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐│  ║  │                    │ ║
║  │  ║  │  │ Benchmark   │ │ Latency     │ │ Memory      │ │ Carbon      ││  ║  │                    │ ║
║  │  ║  │  │ Runner      │ │ Evaluator   │ │ Evaluator   │ │ Tracker     ││  ║  │                    │ ║
║  │  ║  │  │ ─────────── │ │ ─────────── │ │ ─────────── │ │ ─────────── ││  ║  │                    │ ║
║  │  ║  │  │ lm-eval     │ │ torch.cuda  │ │ peak_memory │ │ codecarbon  ││  ║  │                    │ ║
║  │  ║  │  │ HumanEval   │ │ timing      │ │ per_token   │ │ estimation  ││  ║  │                    │ ║
║  │  ║  │  │ Perplexity  │ │ throughput  │ │             │ │ CO2 grams   ││  ║  │                    │ ║
║  │  ║  │  └─────────────┘ └─────────────┘ └─────────────┘ └─────────────┘│  ║  │                    │ ║
║  │  ║  │                                                                  │  ║  │                    │ ║
║  │  ║  │  Benchmarks: GSM8K, CommonsenseQA, TruthfulQA, HumanEval,       │  ║  │                    │ ║
║  │  ║  │             BIG-Bench Hard, MMLU, HellaSwag, ARC, WinoGrande    │  ║  │                    │ ║
║  │  ║  └─────────────────────────────────────────────────────────────────┘  ║  │                    │ ║
║  │  ╚═══════════════════════════════════════════════════════════════════════╝  │                    │ ║
║  │                           │                                                  │                    │ ║
║  │                           ▼                                                  │                    │ ║
║  │  ╔═══════════════════════════════════════════════════════════════════════╗  │                    │ ║
║  │  ║                      UPDATE STATE NODE                                 ║  │                    │ ║
║  │  ║  ┌─────────────────────────────────────────────────────────────────┐  ║  │                    │ ║
║  │  ║  │                                                                  │  ║  │                    │ ║
║  │  ║  │  1. Pareto Frontier 更新 (src/coordinator/pareto.py)            │  ║  │                    │ ║
║  │  ║  │     ┌─────────────────────────────────────────────────────────┐ │  ║  │                    │ ║
║  │  ║  │     │  5D 最佳化空間:                                          │ │  ║  │                    │ ║
║  │  ║  │     │  • Maximize: accuracy                                    │ │  ║  │                    │ ║
║  │  ║  │     │  • Minimize: latency_ms, memory_gb, model_size_gb, co2  │ │  ║  │                    │ ║
║  │  ║  │     │                                                          │ │  ║  │                    │ ║
║  │  ║  │     │  add_solution() → 檢查支配關係 → 更新 frontier            │ │  ║  │                    │ ║
║  │  ║  │     └─────────────────────────────────────────────────────────┘ │  ║  │                    │ ║
║  │  ║  │                                                                  │  ║  │                    │ ║
║  │  ║  │  2. Skill Memory 記錄 (src/skills/memory.py)                    │  ║  │                    │ ║
║  │  ║  │     record(context, result) → 儲存至磁碟                         │  ║  │                    │ ║
║  │  ║  │                                                                  │  ║  │                    │ ║
║  │  ║  │  3. History 更新 (bounded to 100 entries)                       │  ║  │                    │ ║
║  │  ║  │                                                                  │  ║  │                    │ ║
║  │  ║  │  4. consecutive_no_improvement 計數                              │  ║  │                    │ ║
║  │  ║  │                                                                  │  ║  │                    │ ║
║  │  ║  │  5. 儲存 Episode Artifacts                                       │  ║  │                    │ ║
║  │  ║  └─────────────────────────────────────────────────────────────────┘  ║  │                    │ ║
║  │  ╚═══════════════════════════════════════════════════════════════════════╝  │                    │ ║
║  │                           │                                                  │                    │ ║
║  │                           │ (Loop back)                                      │                    │ ║
║  │                           └──────────────────────────────────────────────────┘                    │ ║
║  │                                              │                                                    │ ║
║  │                                              ▼                                                    │ ║
║  │                                       [COORDINATOR]                                               │ ║
║  │                                              │                                                    │ ║
║  │                                     (termination condition)                                       │ ║
║  │                                              │                                                    │ ║
║  │                                              ▼                                                    │ ║
║  │                                          [END]                                                    │ ║
║  └─────────────────────────────────────────────────────────────────────────────────────────────────┘ ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════╝
                                              │
                                              ▼
┌─────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                          輸出層                                                       │
│                                                                                                      │
│  data/experiments/{experiment_name}/                                                                 │
│  ├── model_spec.json              # 推論出的模型規格                                                   │
│  ├── pareto_frontier.json         # Pareto 最佳解集合                                                 │
│  ├── final_results.json           # 最終結果摘要                                                      │
│  ├── pareto_visualization.html    # 互動式視覺化圖表 (Plotly)                                          │
│  └── episode_{000..999}/                                                                             │
│      ├── strategy.json            # 該 episode 使用的壓縮策略                                          │
│      └── results.json             # 該 episode 的評估結果                                             │
└─────────────────────────────────────────────────────────────────────────────────────────────────────┘


╔══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                      支援模組詳細架構                                                  ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════╝

┌─────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                   src/tools/ (底層實作)                                               │
│                                                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────────────────────────┐    │
│  │                            quantization_wrapper.py                                           │    │
│  │                                                                                              │    │
│  │  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐   │    │
│  │  │ AutoRound   │   │    GPTQ     │   │    AWQ      │   │    INT8     │   │    ASVD     │   │    │
│  │  │ Quantizer   │   │  Quantizer  │   │  Quantizer  │   │  Quantizer  │   │  Compressor │   │    │
│  │  │ ─────────── │   │ ─────────── │   │ ─────────── │   │ ─────────── │   │ ─────────── │   │    │
│  │  │ auto_round  │   │ auto_gptq   │   │ autoawq     │   │ bitsandbytes│   │ SVD rank    │   │    │
│  │  │ library     │   │ library     │   │ library     │   │ library     │   │ reduction   │   │    │
│  │  └─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘   │    │
│  │                                                                                              │    │
│  │  ┌─────────────┐   ┌─────────────┐   ┌─────────────────────────────────────────────────┐   │    │
│  │  │    LoRA     │   │   QLoRA     │   │              Fallback Mock                       │   │    │
│  │  │  Adapter    │   │  Adapter    │   │  (當 library 不可用時自動降級)                     │   │    │
│  │  │ ─────────── │   │ ─────────── │   │                                                  │   │    │
│  │  │ PEFT        │   │ PEFT +      │   │  MockQuantizer → 模擬壓縮結果                     │   │    │
│  │  │ library     │   │ bitsandbytes│   │                                                  │   │    │
│  │  └─────────────┘   └─────────────┘   └─────────────────────────────────────────────────┘   │    │
│  └─────────────────────────────────────────────────────────────────────────────────────────────┘    │
│                                                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────────────────────────┐    │
│  │                              pruning_wrapper.py                                              │    │
│  │  ┌─────────────────────────┐   ┌─────────────────────────┐                                  │    │
│  │  │   Magnitude Pruner      │   │   Structured Pruner     │                                  │    │
│  │  │   (unstructured)        │   │   (channel/head)        │                                  │    │
│  │  └─────────────────────────┘   └─────────────────────────┘                                  │    │
│  └─────────────────────────────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                              src/evaluation/evaluators/ (評估器)                                      │
│                                                                                                      │
│  ┌────────────────────────────────────────────────────────────────────────────────────────────────┐ │
│  │                               base_evaluator.py (抽象基類)                                      │ │
│  │                                       │                                                         │ │
│  │           ┌───────────────────────────┼───────────────────────────┐                            │ │
│  │           │                           │                           │                            │ │
│  │           ▼                           ▼                           ▼                            │ │
│  │  ┌─────────────────┐      ┌─────────────────┐      ┌─────────────────┐                        │ │
│  │  │ lm_eval_        │      │ humaneval_      │      │ latency_        │                        │ │
│  │  │ evaluator.py    │      │ evaluator.py    │      │ evaluator.py    │                        │ │
│  │  │ ─────────────── │      │ ─────────────── │      │ ─────────────── │                        │ │
│  │  │ EleutherAI      │      │ Code execution  │      │ torch.cuda      │                        │ │
│  │  │ lm-eval harness │      │ with timeout    │      │ Events timing   │                        │ │
│  │  │                 │      │ multiprocessing │      │ warmup + runs   │                        │ │
│  │  │ Benchmarks:     │      │                 │      │                 │                        │ │
│  │  │ • GSM8K         │      │                 │      │                 │                        │ │
│  │  │ • CommonsenseQA │      │                 │      │                 │                        │ │
│  │  │ • TruthfulQA    │      │                 │      │                 │                        │ │
│  │  │ • MMLU          │      │                 │      │                 │                        │ │
│  │  │ • HellaSwag     │      │                 │      │                 │                        │ │
│  │  │ • ARC           │      │                 │      │                 │                        │ │
│  │  │ • WinoGrande    │      │                 │      │                 │                        │ │
│  │  │ • BIG-Bench     │      │                 │      │                 │                        │ │
│  │  └─────────────────┘      └─────────────────┘      └─────────────────┘                        │ │
│  │           │                                                   │                                │ │
│  │           ▼                                                   ▼                                │ │
│  │  ┌─────────────────┐                              ┌─────────────────┐                         │ │
│  │  │ perplexity_     │                              │ Energy Tracker  │                         │ │
│  │  │ evaluator.py    │                              │ (codecarbon)    │                         │ │
│  │  │ ─────────────── │                              │ ─────────────── │                         │ │
│  │  │ Cross-entropy   │                              │ CO2 estimation  │                         │ │
│  │  │ loss based      │                              │ kWh tracking    │                         │ │
│  │  └─────────────────┘                              └─────────────────┘                         │ │
│  └────────────────────────────────────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                   src/skills/ (技能系統)                                              │
│                                                                                                      │
│  ┌────────────────────────────────────────────────────────────────────────────────────────────────┐ │
│  │                                                                                                 │ │
│  │  ┌─────────────────┐          ┌─────────────────┐          ┌─────────────────┐                 │ │
│  │  │   registry.py   │          │   pipeline.py   │          │   memory.py     │                 │ │
│  │  │ ─────────────── │          │ ─────────────── │          │ ─────────────── │                 │ │
│  │  │ 動態發現可用的   │   ──►   │ Pipeline 組合   │   ◄──    │ 跨實驗學習      │                 │ │
│  │  │ 壓縮方法        │          │ Step1→Step2→..  │          │ 記錄成功策略    │                 │ │
│  │  │ 檢查 library    │          │ 條件式執行      │          │ 推薦最佳策略    │                 │ │
│  │  │ 回報給 LLM      │          │ 錯誤處理        │          │ 基於相似度匹配  │                 │ │
│  │  └─────────────────┘          └─────────────────┘          └─────────────────┘                 │ │
│  │           │                           │                           │                            │ │
│  │           ▼                           ▼                           ▼                            │ │
│  │  ┌─────────────────┐          ┌─────────────────┐          ┌─────────────────┐                 │ │
│  │  │   schema.py     │          │  templates.py   │          │ data/skills/    │                 │ │
│  │  │ ─────────────── │          │ ─────────────── │          │ ─────────────── │                 │ │
│  │  │ SkillDefinition │          │ 預設 Pipeline:  │          │ memory.json     │                 │ │
│  │  │ SkillContext    │          │ • aggressive    │          │ (持久化儲存)    │                 │ │
│  │  │ SkillResult     │          │ • balanced      │          │                 │                 │ │
│  │  │ SkillRecommend  │          │ • quick_eval    │          │                 │                 │ │
│  │  └─────────────────┘          │ • accuracy_focus│          └─────────────────┘                 │ │
│  │                               └─────────────────┘                                               │ │
│  └────────────────────────────────────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                  src/common/ (共用模組)                                               │
│                                                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────────────────────────┐    │
│  │                                  schemas.py                                                  │    │
│  │  ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐     │    │
│  │  │ CompressionMethod│   │    Benchmark    │   │   ModelSpec     │   │EvaluationResult │     │    │
│  │  │ (Enum)          │   │    (Enum)       │   │   (Pydantic)    │   │   (Pydantic)    │     │    │
│  │  │ ─────────────── │   │ ─────────────── │   │ ─────────────── │   │ ─────────────── │     │    │
│  │  │ AUTOROUND       │   │ GSM8K           │   │ model_size_gb   │   │ accuracy        │     │    │
│  │  │ GPTQ            │   │ COMMONSENSEQA   │   │ model_family    │   │ latency_ms      │     │    │
│  │  │ INT8            │   │ TRUTHFULQA      │   │ min_vram_gb     │   │ memory_gb       │     │    │
│  │  │ AWQ             │   │ HUMANEVAL       │   │ recommended_    │   │ model_size_gb   │     │    │
│  │  │ ASVD            │   │ BIGBENCH_HARD   │   │   vram_gb       │   │ co2_grams       │     │    │
│  │  │ PRUNING         │   │ MMLU            │   │ preferred_      │   │ is_pareto_      │     │    │
│  │  │ DISTILLATION    │   │ HELLASWAG       │   │   methods       │   │   optimal       │     │    │
│  │  │ LORA            │   │ ARC             │   │                 │   │ benchmark_      │     │    │
│  │  │ QLORA           │   │ WINOGRANDE      │   │                 │   │   scores        │     │    │
│  │  └─────────────────┘   └─────────────────┘   └─────────────────┘   └─────────────────┘     │    │
│  │                                                                                              │    │
│  │  ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐                            │    │
│  │  │Compression      │   │ ParetoSolution  │   │    Episode      │                            │    │
│  │  │  Strategy       │   │   (Pydantic)    │   │   (Pydantic)    │                            │    │
│  │  │   (Pydantic)    │   │ ─────────────── │   │ ─────────────── │                            │    │
│  │  │ ─────────────── │   │ strategy        │   │ episode_id      │                            │    │
│  │  │ episode_id      │   │ result          │   │ strategy        │                            │    │
│  │  │ methods         │   │ dominates_list  │   │ result          │                            │    │
│  │  │ quantization_   │   │                 │   │ status          │                            │    │
│  │  │   bits          │   │                 │   │ error_message   │                            │    │
│  │  │ pruning_ratio   │   │                 │   │                 │                            │    │
│  │  │ lora_rank       │   │                 │   │                 │                            │    │
│  │  └─────────────────┘   └─────────────────┘   └─────────────────┘                            │    │
│  └─────────────────────────────────────────────────────────────────────────────────────────────┘    │
│                                                                                                      │
│  ┌─────────────────────────────────────────────────────────────────────────────────────────────┐    │
│  │                                 model_utils.py                                               │    │
│  │  ┌───────────────────────────────────────────────────────────────────────────────────────┐  │    │
│  │  │                        MODEL_SIZE_DATABASE (100+ models)                               │  │    │
│  │  │  ─────────────────────────────────────────────────────────────────────────────────────│  │    │
│  │  │  "gpt2": 0.5GB, "gpt2-medium": 1.4GB, "gpt2-large": 3.0GB, "gpt2-xl": 6.0GB          │  │    │
│  │  │  "meta-llama/Llama-2-7b-hf": 14.0GB, "meta-llama/Llama-3-8B": 16.0GB                  │  │    │
│  │  │  "mistralai/Mistral-7B-v0.1": 14.0GB, "mistralai/Mixtral-8x7B": 93.0GB               │  │    │
│  │  │  "microsoft/phi-2": 5.5GB, "Qwen/Qwen2-7B": 14.0GB                                    │  │    │
│  │  │  ... and 90+ more models                                                              │  │    │
│  │  └───────────────────────────────────────────────────────────────────────────────────────┘  │    │
│  │                                                                                              │    │
│  │  Functions: estimate_model_size(), get_model_family(), get_model_info_from_hub()            │    │
│  └─────────────────────────────────────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────────────────────────────────────┘


╔══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                    資料流向總覽                                                        ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════╝

   User Input                                                                  Output Files
   ─────────                                                                   ────────────
 ┌──────────┐                                                              ┌────────────────┐
 │model_name│─┐                                                            │model_spec.json │
 │dataset   │ │                                                            │pareto_frontier │
 │episodes  │ │                                                       ┌───►│final_results   │
 │budget    │ │                                                       │    │visualization   │
 └──────────┘ │                                                       │    │episode_XXX/    │
              │                                                       │    └────────────────┘
              ▼                                                       │
    ┌─────────────────┐      ┌─────────────────┐      ┌──────────────┴────┐
    │  Spec Inference │─────►│    Initial      │─────►│   LangGraph       │
    │  (HF Hub/DB)    │      │    State        │      │   State Machine   │
    └─────────────────┘      └─────────────────┘      │                   │
                                                      │  ┌─────────────┐  │
    ┌─────────────────┐                               │  │ Coordinator │  │
    │  Skill Memory   │◄──────────────────────────────┤  │  (GPT-4o)   │  │
    │  (歷史學習)      │──────────────────────────────►│  └──────┬──────┘  │
    └─────────────────┘                               │         │         │
                                                      │         ▼         │
    ┌─────────────────┐                               │  ┌─────────────┐  │
    │  Quantization   │◄──────────────────────────────┤  │   Workers   │  │
    │  Wrappers       │──────────────────────────────►│  │(Quant/Prune)│  │
    │  (AutoRound..)  │                               │  └──────┬──────┘  │
    └─────────────────┘                               │         │         │
                                                      │         ▼         │
    ┌─────────────────┐                               │  ┌─────────────┐  │
    │  Evaluators     │◄──────────────────────────────┤  │ Evaluation  │  │
    │  (lm-eval,      │──────────────────────────────►│  │    Node     │  │
    │   latency, CO2) │                               │  └──────┬──────┘  │
    └─────────────────┘                               │         │         │
                                                      │         ▼         │
    ┌─────────────────┐                               │  ┌─────────────┐  │
    │  Pareto         │◄──────────────────────────────┤  │Update State │──┼───►
    │  Frontier       │──────────────────────────────►│  │    Node     │  │
    │  (5D 最佳化)     │                               │  └─────────────┘  │
    └─────────────────┘                               └───────────────────┘


╔══════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                    外部依賴關係                                                        ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════╝

    ┌───────────────────────────────────────────────────────────────────────────────────────────────┐
    │                                    External Services                                           │
    │                                                                                                │
    │  ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐       │
    │  │   OpenAI API    │   │ HuggingFace Hub │   │   CodeCarbon    │   │   CUDA/GPU      │       │
    │  │   (GPT-4o)      │   │   (Models)      │   │   (CO2 Track)   │   │   (Inference)   │       │
    │  └────────┬────────┘   └────────┬────────┘   └────────┬────────┘   └────────┬────────┘       │
    │           │                     │                     │                     │                 │
    └───────────┼─────────────────────┼─────────────────────┼─────────────────────┼─────────────────┘
                │                     │                     │                     │
                ▼                     ▼                     ▼                     ▼
    ┌───────────────────────────────────────────────────────────────────────────────────────────────┐
    │                                    Python Libraries                                            │
    │                                                                                                │
    │  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐   │
    │  │ LangGraph  │ │ LangChain  │ │Transformers│ │   PEFT     │ │ auto_round │ │ auto_gptq  │   │
    │  │            │ │  OpenAI    │ │            │ │ (LoRA)     │ │            │ │            │   │
    │  └────────────┘ └────────────┘ └────────────┘ └────────────┘ └────────────┘ └────────────┘   │
    │  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐   │
    │  │  autoawq   │ │bitsandbytes│ │  lm-eval   │ │  datasets  │ │   torch    │ │  Pydantic  │   │
    │  │            │ │  (INT8)    │ │  harness   │ │ (HF)       │ │            │ │            │   │
    │  └────────────┘ └────────────┘ └────────────┘ └────────────┘ └────────────┘ └────────────┘   │
    └───────────────────────────────────────────────────────────────────────────────────────────────┘
```

## 目錄結構

```
src/
├── common/                    # 共用工具和 schemas
│   ├── schemas.py            # Pydantic 資料模型
│   └── model_utils.py        # 模型大小資料庫、估算工具
├── coordinator/              # LangGraph 協調層
│   ├── langgraph_coordinator.py  # 主要多代理協調器 (GPT-4o 驅動)
│   ├── state.py             # LangGraph 狀態 schema 和工具
│   ├── pareto.py            # 多目標 Pareto frontier 追蹤
│   ├── spec_inference.py    # 從模型名稱自動推論規格
│   └── strategy_generator.py # 策略生成邏輯
├── agents/                   # 專業 Worker Agents (LangChain tools)
│   ├── quantization_agent.py     # 量化 (AutoRound, GPTQ, AWQ, INT8, ASVD, LoRA, QLoRA)
│   ├── evaluation_agent.py       # Benchmark 評估和效能測量
│   ├── search_agent.py          # 搜尋演算法 (Bayesian, Evolutionary, MAB)
│   ├── pruning_agent.py         # 剪枝壓縮 (magnitude & structured)
│   ├── distillation_agent.py    # 模型蒸餾
│   ├── finetune_agent.py        # 微調工具
│   ├── data_manager_agent.py    # 資料管理
│   └── resource_monitor_agent.py # GPU/記憶體監控
├── evaluation/              # 評估基礎設施
│   ├── benchmark_runner.py  # 主要評估協調器
│   └── evaluators/
│       ├── base_evaluator.py       # 所有評估器的基類
│       ├── lm_eval_evaluator.py    # EleutherAI lm-eval harness 包裝
│       ├── humaneval_evaluator.py  # HumanEval 程式碼執行
│       ├── latency_evaluator.py    # 推論延遲測量
│       └── perplexity_evaluator.py # Perplexity 計算
├── tools/                   # 壓縮實作包裝
│   ├── quantization_wrapper.py  # 量化器實作
│   └── pruning_wrapper.py      # 剪枝器實作
├── skills/                  # 動態技能發現和學習
│   ├── registry.py         # 技能註冊和發現
│   ├── pipeline.py         # 多步驟 pipeline 組合
│   ├── memory.py           # 從歷史學習技能
│   ├── schema.py           # 技能資料模型
│   └── templates.py        # 預定義 pipeline 模板
├── reward/                  # 多目標獎勵函數
│   └── reward_function.py   # 獎勵計算
├── api/                     # API 端點
│   ├── main.py             # FastAPI 伺服器
│   └── celery_app.py       # 非同步任務佇列
└── __init__.py
```

## 核心元件關係

| 元件 | 依賴 | 被使用於 |
|------|------|----------|
| **LangGraphCoordinator** | 所有 agents, State, ParFrontier, Skills | scripts/run_pipeline.py |
| **Coordinator Node** | ModelSpec, SkillMemory, ParFrontier | Graph 執行 |
| **Worker Nodes** | Quantizer/Pruner/Pipeline tools | Coordinator 路由 |
| **Evaluation Node** | BenchmarkRunner, LatencyEval, Energy | Worker 輸出 |
| **Update State Node** | ParFrontier, SkillMemory | Evaluation 結果 |
| **Skill Memory** | SkillContext, SkillResult | Coordinator (推薦) |
| **Pipeline** | SkillDefinitions | Coordinator (pipeline action) |
| **ParFrontier** | CompressionStrategy, EvaluationResult | Update State |
| **BenchmarkRunner** | LMEvalEvaluator, HumanEvalEvaluator | Evaluation agent |
| **ModelSpec** | model_utils, Hub API | Coordinator 初始化 |

## 終止條件

1. `max_episodes` 達到上限
2. `time_budget` 超時
3. 收斂 (連續 5 個 episode 無 Pareto 改進)

## 系統特性

- **自主性**: GPT-4o 在無人工干預下做出所有壓縮決策
- **多目標**: 平衡 accuracy, latency, memory, size, CO2 排放
- **學習性**: Skill memory 根據歷史結果調整推薦
- **可組合**: Pipeline 可串連多種技術 (pruning → quantization → LoRA)
- **容錯性**: 當 libraries/APIs 不可用時優雅降級
- **迭代性**: 基於 episode 的工作流程，具收斂偵測
- **透明性**: 儲存所有中間結果和視覺化
- **綠色 AI**: 追蹤並優化碳排放
